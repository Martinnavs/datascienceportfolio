{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "484695e9",
   "metadata": {},
   "source": [
    "Navarez, AM P\n",
    "CMSC 173 Week 6 Assignment\n",
    "\n",
    "One way of improving the performance of the multiclass classification is to utilize divide-and-conquer. This is done by creating a binary tree of classifiers, which operates using the following principles:\n",
    "\n",
    "    1. The generation of nodes involves the splitting of the classes into two groups.\n",
    "    2. The inner nodes represent the binary classifiers, while the leaf nodes represent the classes.\n",
    "    3. The dataset is labelled based on whether or not the label/class belongs to the first, which may be done through assigning them binary values.\n",
    "        ◦ For groups with an odd number of classes, the one-versus-all labelling method may be used.\n",
    "    4. A binary classifier is trained on this new dataset, which also serves as a new inner node in the tree.\n",
    "        ◦ The inner node produces two nodes, which may either be another classifier (in which we do another recursive call using the dataset with the binary value corresponding to its corresponding group), or a class value.\n",
    "        ◦ The reason why one-versus-all may be used for an odd-numbered group is because it produces a class value node and an inner node rather than two inner nodes, which ensures an even number of classes in the next splitting.\n",
    "    5. Since the created classifier is binary, the prediction will also be binary. One can look at the actual output of the prediction rather than the scores.\n",
    "    6. The prediction results determines the manner in which a feature value follows until it reaches a leaf node, which determines its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f467b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39cb470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [1 2 3 5 6 7]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Class\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0      1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0      1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0      1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0      1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/glass.csv'\n",
    "\n",
    "names = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Class']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "index_size = df.shape[0]\n",
    "print(\"Classes: \" + str(df['Class'].unique()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6716f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872868</td>\n",
       "      <td>0.284953</td>\n",
       "      <td>1.254639</td>\n",
       "      <td>-0.692442</td>\n",
       "      <td>-1.127082</td>\n",
       "      <td>-0.671705</td>\n",
       "      <td>-0.145766</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249333</td>\n",
       "      <td>0.591817</td>\n",
       "      <td>0.636168</td>\n",
       "      <td>-0.170460</td>\n",
       "      <td>0.102319</td>\n",
       "      <td>-0.026213</td>\n",
       "      <td>-0.793734</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.721318</td>\n",
       "      <td>0.149933</td>\n",
       "      <td>0.601422</td>\n",
       "      <td>0.190912</td>\n",
       "      <td>0.438787</td>\n",
       "      <td>-0.164533</td>\n",
       "      <td>-0.828949</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.232831</td>\n",
       "      <td>-0.242853</td>\n",
       "      <td>0.698710</td>\n",
       "      <td>-0.310994</td>\n",
       "      <td>-0.052974</td>\n",
       "      <td>0.112107</td>\n",
       "      <td>-0.519052</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.312045</td>\n",
       "      <td>-0.169205</td>\n",
       "      <td>0.650066</td>\n",
       "      <td>-0.411375</td>\n",
       "      <td>0.555256</td>\n",
       "      <td>0.081369</td>\n",
       "      <td>-0.624699</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RI        Na        Mg        Al        Si         K        Ca  \\\n",
       "0  0.872868  0.284953  1.254639 -0.692442 -1.127082 -0.671705 -0.145766   \n",
       "1 -0.249333  0.591817  0.636168 -0.170460  0.102319 -0.026213 -0.793734   \n",
       "2 -0.721318  0.149933  0.601422  0.190912  0.438787 -0.164533 -0.828949   \n",
       "3 -0.232831 -0.242853  0.698710 -0.310994 -0.052974  0.112107 -0.519052   \n",
       "4 -0.312045 -0.169205  0.650066 -0.411375  0.555256  0.081369 -0.624699   \n",
       "\n",
       "         Ba        Fe  Class  \n",
       "0 -0.352877 -0.586451      1  \n",
       "1 -0.352877 -0.586451      1  \n",
       "2 -0.352877 -0.586451      1  \n",
       "3 -0.352877 -0.586451      1  \n",
       "4 -0.352877 -0.586451      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "scaled_df = pd.DataFrame(X, columns=names[:-1])\n",
    "scaled_df['Class'] = y\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d72de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
    "Splitting the dataset into training and testing. Train-test-split is not \n",
    "used on the training dataset as the feature-label splitting will be done \n",
    "during the training process.\n",
    "\"\"\"\n",
    "train, test = np.split(scaled_df.sample(frac=1, random_state=100),\n",
    "                      [int(.8 * len(df))])\n",
    "\n",
    "# split test dataset into features and labels\n",
    "X_test = test.drop('Class', axis=1)\n",
    "y_test = test['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869aa14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree data structure\n",
    "class TreeNode:\n",
    "    def __init__(self, model, left=None, right=None, name=\"\"):\n",
    "        self.model = model\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name if isinstance(self.name, str) else str(self.name)\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        return self.right == None and self.left == None\n",
    "\n",
    "    def height(self):\n",
    "        if self.isLeaf():\n",
    "            return 1\n",
    "        return 1 + max(self.left.height(), self.right.height())\n",
    "    \n",
    "    def predict_inner(self, feature_vector, verbose=False):\n",
    "        \"\"\"\n",
    "        Predicts a single feature vector, returns a prediction value\n",
    "        \"\"\"\n",
    "        \n",
    "        prediction_value = self.model.predict(feature_vector)\n",
    "\n",
    "        if verbose:\n",
    "            print(str(self) + \" classifier predicted that the value belongs to the\" + \n",
    "                    (\" left group\" if prediction_value == 1 else \" right group\" if prediction_value == 0 else \"\"), \n",
    "                  end = ' ')\n",
    "        \n",
    "        if not self.left.isLeaf() and prediction_value == 1:\n",
    "            # classified as part of the left group\n",
    "            if verbose: print(\".\\n\")\n",
    "            return self.left.predict_inner(feature_vector, verbose)\n",
    "        elif not self.right.isLeaf() and prediction_value == 0:\n",
    "            if verbose: print(\".\\n\")\n",
    "            # classified as part of the right group\n",
    "            return self.right.predict_inner(feature_vector, verbose)\n",
    "        else:\n",
    "            # classifying on values, still follows left vs right\n",
    "            if prediction_value == 1:\n",
    "                if verbose: print(\"with value \" + str(self.left))\n",
    "                return self.left.name\n",
    "            else:\n",
    "                if verbose: print(\"with value \" + str(self.right))\n",
    "                return self.right.name\n",
    "            \n",
    "            \n",
    "    def predict(self, feature_set, verbose=False):\n",
    "        \"\"\"\n",
    "        Predicts an entire feature set, returns a prediction array\n",
    "        \"\"\"\n",
    "        predictions = np.array([])\n",
    "        if isinstance(feature_set, pd.Series):\n",
    "            feature_vec = feature_set.values.reshape(1, 9)\n",
    "            predictions = np.append(predictions, Multiclass_classifier.predict_inner(feature_vec, verbose))\n",
    "        else:\n",
    "            for i in range(len(feature_set)):\n",
    "                feature_vec = feature_set.iloc[i].to_numpy()\n",
    "                feature_vec = feature_vec.reshape(1, 9)\n",
    "                predictions = np.append(predictions, Multiclass_classifier.predict_inner(feature_vec, verbose))\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "    def score(self, test_features, test_labels, verbose=False):\n",
    "        \"\"\"\n",
    "        Scores the predictions made. Formula is:\n",
    "        \n",
    "        Score = Count of correct labels / Count of all labels\n",
    "        \"\"\"\n",
    "        \n",
    "        predicted_labels = self.predict(test_features, verbose)\n",
    "        return np.sum(predicted_labels == test_labels) / len(test_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a326ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/34012886/print-binary-tree-level-by-level-in-python\n",
    "def print_tree(root, val=\"val\", left=\"left\", right=\"right\"):\n",
    "    def display(root, val=val, left=left, right=right):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if getattr(root, right) is None and getattr(root, left) is None:\n",
    "            line = str(root)\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "\n",
    "        # Only left child.\n",
    "        if getattr(root, right) is None:\n",
    "            lines, n, p, x = display(getattr(root, left))\n",
    "            s = str(root)\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s\n",
    "            second_line = x * ' ' + '/' + (n - x - 1 + u) * ' '\n",
    "            shifted_lines = [line + u * ' ' for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "\n",
    "        # Only right child.\n",
    "        if getattr(root, left) is None:\n",
    "            lines, n, p, x = display(getattr(root, right))\n",
    "            s = str(root)\n",
    "            u = len(s)\n",
    "            first_line = s + x * '_' + (n - x) * ' '\n",
    "            second_line = (u + x) * ' ' + '\\\\' + (n - x - 1) * ' '\n",
    "            shifted_lines = [u * ' ' + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "\n",
    "        # Two children.\n",
    "        left, n, p, x = display(getattr(root, left))\n",
    "        right, m, q, y = display(getattr(root, right))\n",
    "        s = str(root)\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s + y * '_' + (m - y) * ' '\n",
    "        second_line = x * ' ' + '/' + (n - x - 1 + u + y) * ' ' + '\\\\' + (m - y - 1) * ' '\n",
    "        if p < q:\n",
    "            left += [n * ' '] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * ' '] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * ' ' + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2\n",
    "\n",
    "    lines, *_ = display(root, val, left, right)\n",
    "    for line in lines:\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c31380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiclass(Dataset, model):\n",
    "    new_dataset = Dataset.copy() # deep copying dataset, may consume much space for larger datasets\n",
    "    all_classes = new_dataset['Class'].unique() # get all label values\n",
    "    all_classes.sort()\n",
    "    \n",
    "    if len(all_classes)%2 == 0:\n",
    "        # group dataset evenly\n",
    "        left_group = all_classes[:len(all_classes)//2]\n",
    "        right_group = all_classes[len(all_classes)//2:]\n",
    "    else:\n",
    "        # one-vs-all grouping\n",
    "        left_group = [all_classes[0].astype(np.int32)]\n",
    "        right_group = list(all_classes[1:])\n",
    "    \n",
    "    # binary labelling as to a class belongs to the left group or not\n",
    "    is_inleft = lambda val: int(val in left_group)\n",
    "    new_dataset['new_Class'] = new_dataset['Class'].apply(is_inleft)\n",
    "    \n",
    "    # creating the features and labels\n",
    "    X = new_dataset.drop(['new_Class','Class'], axis=1)\n",
    "    y = new_dataset['new_Class']\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=173)\n",
    "    \n",
    "    # creating a new binary classifier \n",
    "    new_model = clone(model)\n",
    "    new_model.fit(X_train,y_train)\n",
    "    \n",
    "    left = None\n",
    "    right = None\n",
    "    name = str(left_group) + \" vs. \" + str(right_group)\n",
    "    print(name + \" Score: \" + str(new_model.score(X_test, y_test)))\n",
    "    \n",
    "    if len(left_group) > 1:\n",
    "        # inner node\n",
    "        left = train_multiclass(Dataset[Dataset['Class'].isin(left_group)], model)\n",
    "    else:\n",
    "        # leaf node, no models\n",
    "        left = TreeNode(None, name=left_group[0])\n",
    "    \n",
    "    if len(right_group) > 1:\n",
    "        # inner node\n",
    "        right = train_multiclass(Dataset[Dataset['Class'].isin(right_group)], model)\n",
    "    else:\n",
    "        # leaf node, no models\n",
    "        right = TreeNode(None, name=right_group[0])\n",
    "        \n",
    "    return TreeNode(new_model, left, right, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "387a6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] vs. [5 6 7] Score: 0.9142857142857143\n",
      "[1] vs. [2, 3] Score: 0.7692307692307693\n",
      "[2] vs. [3] Score: 0.7142857142857143\n",
      "[5] vs. [6, 7] Score: 0.8888888888888888\n",
      "[6] vs. [7] Score: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Testing multiclass classification using models discussed in class.\n",
    "No hyperparameter tuning was done since this is only intended as a\n",
    "proof-of-concept.\n",
    "\"\"\"\n",
    "\n",
    "# perceptron = Perceptron(max_iter=3)\n",
    "# Multiclass_classifier = train_multiclass(train, perceptron)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "Multiclass_classifier = train_multiclass(train, decision_tree)\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=4)\n",
    "# Multiclass_classifier = train_multiclass(train, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f20e66f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ___________________[1 2 3] vs. [5 6 7]________                    \n",
      "        /                                              \\                   \n",
      " [1] vs. [2, 3]______                           [5] vs. [6, 7]______       \n",
      "/                    \\                         /                    \\      \n",
      "1               [2] vs. [3]                    5               [6] vs. [7] \n",
      "               /           \\                                  /           \\\n",
      "               2           3                                  6           7\n"
     ]
    }
   ],
   "source": [
    "print_tree(Multiclass_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eeea0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6744186046511628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Multiclass_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7ab47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3] vs. [5 6 7] classifier predicted that the value belongs to the left group .\n",
      "\n",
      "[1] vs. [2, 3] classifier predicted that the value belongs to the right group .\n",
      "\n",
      "[2] vs. [3] classifier predicted that the value belongs to the left group with value 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing a verbose prediction\n",
    "Multiclass_classifier.predict(X_test.iloc[0], verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
