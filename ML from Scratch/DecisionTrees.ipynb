{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb9dfe3",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "This notebook contains the implementation of a decision tree using the following criterion:\n",
    "\n",
    "1. Chi-square\n",
    "<br>\n",
    "2. Gini Impurity\n",
    "<br>\n",
    "3. Number of correct guesses (provided in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c98fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load the csv\n",
    "csv = np.genfromtxt('movie.csv', delimiter=',')\n",
    "\n",
    "# remove header\n",
    "csv = csv[1:]\n",
    "\n",
    "# convert ratings from +2, +1, 0, -1, -2 to 0 to 2 for like\n",
    "# and -1 to -2 for dislike\n",
    "base_ratings = csv[:, 0]\n",
    "base_ratings[base_ratings >= 0] = 1\n",
    "base_ratings[base_ratings < 0] = -1\n",
    "\n",
    "# shuffle data\n",
    "np.random.shuffle(csv)\n",
    "\n",
    "# split data 80/20 training/test\n",
    "training_size = int(csv.shape[0] * 0.8)\n",
    "training_data = csv[:training_size]\n",
    "test_data = csv[training_size:]\n",
    "\n",
    "# separate dataset into the label and the feature values\n",
    "# training_data = csv\n",
    "ratings = np.array(training_data[:, 0])\n",
    "examples = np.array(training_data[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796a7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree data structure\n",
    "class TreeNode:\n",
    "    def __init__(self, value, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def isLeaf(self):\n",
    "        return self.right == None and self.left == None\n",
    "\n",
    "    def height(self):\n",
    "        if self.isLeaf():\n",
    "            return 1\n",
    "        return 1 + max(self.left.height(), self.right.height())\n",
    "    \n",
    "    def inorder(self):\n",
    "        if self.left is not None:\n",
    "            self.left.inorder()\n",
    "        print(self.value)\n",
    "        if self.right is not None:\n",
    "            self.right.inorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9cc7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/34012886/print-binary-tree-level-by-level-in-python\n",
    "def print_tree(root, val=\"val\", left=\"left\", right=\"right\"):\n",
    "    def display(root, val=val, left=left, right=right):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if getattr(root, right) is None and getattr(root, left) is None:\n",
    "            line = str(root.value)\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "\n",
    "        # Only left child.\n",
    "        if getattr(root, right) is None:\n",
    "            lines, n, p, x = display(getattr(root, left))\n",
    "            s = str(root.value)\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s\n",
    "            second_line = x * ' ' + '/' + (n - x - 1 + u) * ' '\n",
    "            shifted_lines = [line + u * ' ' for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "\n",
    "        # Only right child.\n",
    "        if getattr(root, left) is None:\n",
    "            lines, n, p, x = display(getattr(root, right))\n",
    "            s = str(root.value)\n",
    "            u = len(s)\n",
    "            first_line = s + x * '_' + (n - x) * ' '\n",
    "            second_line = (u + x) * ' ' + '\\\\' + (n - x - 1) * ' '\n",
    "            shifted_lines = [u * ' ' + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "\n",
    "        # Two children.\n",
    "        left, n, p, x = display(getattr(root, left))\n",
    "        right, m, q, y = display(getattr(root, right))\n",
    "        s = str(root.value)\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s + y * '_' + (m - y) * ' '\n",
    "        second_line = x * ' ' + '/' + (n - x - 1 + u + y) * ' ' + '\\\\' + (m - y - 1) * ' '\n",
    "        if p < q:\n",
    "            left += [n * ' '] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * ' '] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * ' ' + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2\n",
    "\n",
    "    lines, *_ = display(root, val, left, right)\n",
    "    for line in lines:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660247b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction function\n",
    "def predict(tree, x):\n",
    "    if tree.isLeaf(): # if leaf, value must be the prediction\n",
    "        return tree.value\n",
    "\n",
    "    feature = tree.value # else, value is a feature to query on\n",
    "\n",
    "    # if the feature to query on is false, predict with left tree\n",
    "    if not x[feature]:\n",
    "        return predict(tree.left, x)\n",
    "    else: # else, predict with right\n",
    "        return predict(tree.right, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821f9c6",
   "metadata": {},
   "source": [
    "## Chi-square\n",
    "\n",
    "Following the ideas presented [in this resource](https://www.analyticsvidhya.com/blog/2021/03/how-to-select-best-split-in-decision-trees-using-chi-square/), I implement a decision tree with chi-square as the splitting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ebcddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of 1 to 0 values of the original dataset\n",
      "1 counts: 12\n",
      "0 counts: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratio of 1 to 0 values of the original dataset\")\n",
    "print(\"1 counts:\", sum(base_ratings == 1))\n",
    "print(\"0 counts:\", sum(base_ratings == -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75a3e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(actual, expected):\n",
    "    if expected == 0:\n",
    "        expected = 1\n",
    "    return np.sqrt(((actual - expected) ** 2) / expected)\n",
    "\n",
    "# training function\n",
    "def train_chi(x, y, features):\n",
    "        \n",
    "        y_sum = np.sum(y) # take summation of y\n",
    "\n",
    "        if y_sum == 0: # if our sum is 0, then they're 50/50 positive/negative labels\n",
    "            y_sum = 1 # arbitrarily set it to positive\n",
    "\n",
    "        guess = np.sign(y_sum) # take the sign of y_sum, majority label will win in this case\n",
    "\n",
    "        if np.all(y == 1) or np.all(y == -1): # if labels were all 1 or all -1, there's no other guess\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        if not features: # there are no more features to query on\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        # calculate percentage to be used in getting expected value\n",
    "        no_percentage =  sum(y == 0) / y.shape[0]\n",
    "        yes_percentage =  sum(y == 1) / y.shape[0]\n",
    "        \n",
    "        chi_square_val = {}\n",
    "        for feature in features:\n",
    "            # split examples according to x[feature] is 0 or 1\n",
    "            x_no = x[x[:, feature] == 0]\n",
    "            x_yes = x[x[:, feature] == 1]\n",
    "\n",
    "            # split label according to x[feature] being 0 or 1\n",
    "            y_no = y[x[:, feature] == 0]\n",
    "            y_yes = y[x[:, feature] == 1]\n",
    "            \n",
    "            # getting split+label pairs\n",
    "            expected_no_no = x_no.shape[0] * no_percentage\n",
    "            actual_no_no = sum(y_no == 0)\n",
    "            \n",
    "            expected_no_yes = x_no.shape[0] * no_percentage\n",
    "            actual_no_yes = sum(y_no == 1)\n",
    "\n",
    "            expected_yes_no = x_yes.shape[0] * yes_percentage\n",
    "            actual_yes_no = sum(y_yes == 0)\n",
    "            \n",
    "            expected_yes_yes = x_yes.shape[0] * yes_percentage\n",
    "            actual_yes_yes = sum(y_yes == 1)\n",
    "            \n",
    "            # calculating chi square value for each split+label pair\n",
    "            no_no_cs = chi_square(expected_no_no, actual_no_no)\n",
    "            no_yes_cs = chi_square(expected_no_yes, actual_no_yes)\n",
    "            yes_no_cs = chi_square(expected_yes_no, actual_yes_no)\n",
    "            yes_yes_cs = chi_square(expected_yes_yes, actual_yes_yes)\n",
    "\n",
    "            # getting feature chi square value\n",
    "            chi_square_val[feature] = no_no_cs + no_yes_cs + yes_no_cs + yes_yes_cs\n",
    "\n",
    "        best_feature = max(chi_square_val, key=chi_square_val.get) # take feature with the best score\n",
    "        remaining_features = [feature for feature in features if feature != best_feature] # new list of features, less the best feature\n",
    "        \n",
    "        # split examples and labels where best_feature is 0 or 1\n",
    "        x_best_no = x[x[:, best_feature] == 0]\n",
    "        y_best_no = y[x[:, best_feature] == 0]\n",
    "\n",
    "        x_best_yes = x[x[:, best_feature] == 1]\n",
    "        y_best_yes = y[x[:, best_feature] == 1]\n",
    "\n",
    "        if len(remaining_features) == 0:\n",
    "            return TreeNode(1)\n",
    "        \n",
    "        left = train_chi(x_best_no, y_best_no, remaining_features)\n",
    "        right = train_chi(x_best_yes, y_best_yes, remaining_features)\n",
    "        return TreeNode(best_feature, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619e7622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PRINTING TREE---------\n",
      "     ___1_____    \n",
      "    /         \\   \n",
      "   _2_       _2_  \n",
      "  /   \\     /   \\ \n",
      "-1.0 1.0   _3  1.0\n",
      "          /  \\    \n",
      "          4  1    \n",
      "         / \\      \n",
      "         1 1      \n",
      "\n",
      "SCORE IS:  1.0\n"
     ]
    }
   ],
   "source": [
    "# train the tree\n",
    "tree = train_chi(examples, ratings, list(range(csv.shape[1]-1)))\n",
    "print(\"--------PRINTING TREE---------\")\n",
    "print_tree(tree)\n",
    "print()\n",
    "\n",
    "# score on test data\n",
    "x_test = test_data[:, 1:]\n",
    "y_test = test_data[:, 0]\n",
    "\n",
    "score = 0\n",
    "for x, y in zip(x_test, y_test):\n",
    "    # if we get a +1 it means we got the same sign, it's a correct prediction\n",
    "    if predict(tree, x) * y > 0:\n",
    "        score += 1\n",
    "print(\"SCORE IS: \", score / test_data.shape[0]) # print out score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82aef49",
   "metadata": {},
   "source": [
    "## Gini Impurity\n",
    "\n",
    "This time, we implement a DTree using gini impurity, one of the most common splitting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54ab10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_gini_impurity(pair_no, pair_yes, yes_shape, no_shape):\n",
    "    \n",
    "    def gini_index(val_yes, val_no):\n",
    "        denominator = val_yes + val_no\n",
    "        if denominator == 0:\n",
    "            denominator = 1\n",
    "        return 1 - ((val_yes/(denominator))**2 + (val_no/(denominator))**2)\n",
    "\n",
    "    weighted_gini_impurity = lambda index_yes, index_no, yes, no: (index_yes*(yes/(yes+no))) + (index_no*(no/(yes+no)))\n",
    "\n",
    "    # get gini index for each label\n",
    "    no_gini_index = gini_index(pair_no[0], pair_no[1])\n",
    "    yes_gini_index = gini_index(pair_yes[0], pair_yes[1])\n",
    "    \n",
    "    return weighted_gini_impurity(yes_gini_index, no_gini_index, yes_shape, no_shape)\n",
    "    \n",
    "\n",
    "# training function\n",
    "def train_gini(x, y, features):\n",
    "        \n",
    "        y_sum = np.sum(y) # take summation of y\n",
    "\n",
    "        if y_sum == 0: # if our sum is 0, then they're 50/50 positive/negative labels\n",
    "            y_sum = 1 # arbitrarily set it to positive\n",
    "\n",
    "        guess = np.sign(y_sum) # take the sign of y_sum, majority label will win in this case\n",
    "\n",
    "        if np.all(y == 1) or np.all(y == -1): # if labels were all 1 or all -1, there's no other guess\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        if not features: # there are no more features to query on\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        impurity = {}\n",
    "        for feature in features:\n",
    "#             # split examples according to x[feature] is 0 or 1\n",
    "            x_no = x[x[:, feature] == 0]\n",
    "            x_yes = x[x[:, feature] == 1]\n",
    "\n",
    "            # split label according to x[feature] being 0 or 1\n",
    "            y_no = y[x[:, feature] == 0]\n",
    "            y_yes = y[x[:, feature] == 1]\n",
    "\n",
    "            # split labels according to whether they are 1 or 0\n",
    "            y_no_yes = y_no[y_no > 0].shape[0]\n",
    "            y_no_no = y_no[y_no < 0].shape[0]\n",
    "            y_yes_yes = y_yes[y_yes > 0].shape[0]\n",
    "            y_yes_no = y_yes[y_yes < 0].shape[0]            \n",
    "\n",
    "            # score for this feature is our total score\n",
    "            impurity[feature] = get_weighted_gini_impurity([y_no_yes, y_no_no], [y_yes_yes, y_yes_no], y_yes.shape[0], y_no.shape[0])\n",
    "\n",
    "        best_feature = min(impurity, key=impurity.get) # take feature with the best score\n",
    "        remaining_features = [feature for feature in features if feature != best_feature] # new list of features, less the best feature\n",
    "        \n",
    "        # split examples and labels where best_feature is 0 or 1\n",
    "        x_best_no = x[x[:, best_feature] == 0]\n",
    "        y_best_no = y[x[:, best_feature] == 0]\n",
    "\n",
    "        x_best_yes = x[x[:, best_feature] == 1]\n",
    "        y_best_yes = y[x[:, best_feature] == 1]\n",
    "        \n",
    "        if len(remaining_features) == 0:\n",
    "            return TreeNode(1)\n",
    "        \n",
    "        # train left child\n",
    "        left = train_gini(x_best_no, y_best_no, remaining_features)\n",
    "        # train right child\n",
    "        right = train_gini(x_best_yes, y_best_yes, remaining_features)\n",
    "        return TreeNode(best_feature, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1423a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PRINTING TREE---------\n",
      "     ________2_  \n",
      "    /          \\ \n",
      "   _1____     1.0\n",
      "  /      \\       \n",
      "-1.0    _0_      \n",
      "       /   \\     \n",
      "     -1.0  3     \n",
      "          / \\    \n",
      "          1 1    \n",
      "\n",
      "SCORE IS:  0.75\n"
     ]
    }
   ],
   "source": [
    "# train the tree\n",
    "tree = train_gini(examples, ratings, list(range(csv.shape[1]-1)))\n",
    "print(\"--------PRINTING TREE---------\")\n",
    "print_tree(tree)\n",
    "print()\n",
    "\n",
    "# make a prediction\n",
    "x = [0, 1, 1, 1, 1]\n",
    "# print(predict(tree, x)) # print out prediction\n",
    "\n",
    "# score on test data\n",
    "x_test = test_data[:, 1:]\n",
    "y_test = test_data[:, 0]\n",
    "\n",
    "score = 0\n",
    "for x, y in zip(x_test, y_test):\n",
    "    # if we get a +1 it means we got the same sign, it's a correct prediction\n",
    "    if predict(tree, x) * y > 0:\n",
    "        score += 1\n",
    "print(\"SCORE IS: \", score / test_data.shape[0]) # print out score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f4196",
   "metadata": {},
   "source": [
    "## Count of Correct Guesses\n",
    "\n",
    "This implementation of a DTree is given in the class, with the count of correct guesses as the splitting criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b1d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, features):\n",
    "        y_sum = np.sum(y) # take summation of y\n",
    "\n",
    "        if y_sum == 0: # if our sum is 0, then they're 50/50 positive/negative labels\n",
    "            y_sum = 1 # arbitrarily set it to positive\n",
    "\n",
    "        guess = np.sign(y_sum) # take the sign of y_sum, majority label will win in this case\n",
    "\n",
    "        if np.all(y == 1) or np.all(y == -1): # if labels were all 1 or all -1, there's no other guess\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        if not features: # there are no more features to query on\n",
    "            return TreeNode(guess)\n",
    "\n",
    "        score = {}\n",
    "        for feature in features:\n",
    "            # split examples according to x[feature] is 0 or 1\n",
    "            x_no = x[x[:, feature] == 0]\n",
    "            x_yes = x[x[:, feature] == 1]\n",
    "\n",
    "            # split label according to x[feature] being 0 or 1\n",
    "            y_no = y[x[:, feature] == 0]\n",
    "            y_yes = y[x[:, feature] == 1]\n",
    "\n",
    "            # take majority label as guess\n",
    "            guess_no = np.sign(np.sum(y_no))\n",
    "            guess_yes = np.sign(np.sum(y_yes))\n",
    "\n",
    "            # count number of ratings examples we would get right with our guesses\n",
    "            score_no = np.sum(y_no == guess_no)\n",
    "            score_yes = np.sum(y_yes == guess_yes)\n",
    "\n",
    "            # score for this feature is our total score\n",
    "            score[feature] = score_no + score_yes\n",
    "\n",
    "        best_feature = max(score, key=score.get) # take feature with the best score\n",
    "        remaining_features = [feature for feature in features if feature != best_feature] # new list of features, less the best feature\n",
    "\n",
    "        # split examples and labels where best_feature is 0 or 1\n",
    "        x_best_no = x[x[:, best_feature] == 0]\n",
    "        y_best_no = y[x[:, best_feature] == 0]\n",
    "\n",
    "        x_best_yes = x[x[:, best_feature] == 1]\n",
    "        y_best_yes = y[x[:, best_feature] == 1]\n",
    "\n",
    "        left = train(x_best_no, y_best_no, remaining_features)\n",
    "        right = train(x_best_yes, y_best_yes, remaining_features)\n",
    "        return TreeNode(best_feature, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27c8e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------PRINTING TREE---------\n",
      "     _____________2_  \n",
      "    /               \\ \n",
      "   _0________      1.0\n",
      "  /          \\        \n",
      "-1.0        _3__      \n",
      "           /    \\     \n",
      "          _4  -1.0    \n",
      "         /  \\         \n",
      "        _1  1         \n",
      "       /  \\           \n",
      "     -1.0 1           \n",
      "\n",
      "SCORE IS:  0.75\n"
     ]
    }
   ],
   "source": [
    "# train the tree\n",
    "tree = train(examples, ratings, list(range(csv.shape[1]-1)))\n",
    "print(\"--------PRINTING TREE---------\")\n",
    "print_tree(tree)\n",
    "print()\n",
    "\n",
    "# make a prediction\n",
    "x = [0, 1, 1, 1, 1]\n",
    "# print(predict(tree, x)) # print out prediction\n",
    "\n",
    "# score on test data\n",
    "x_test = test_data[:, 1:]\n",
    "y_test = test_data[:, 0]\n",
    "\n",
    "score = 0\n",
    "for x, y in zip(x_test, y_test):\n",
    "    # if we get a +1 it means we got the same sign, it's a correct prediction\n",
    "    if predict(tree, x) * y > 0:\n",
    "        score += 1\n",
    "print(\"SCORE IS: \", score / test_data.shape[0]) # print out score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
